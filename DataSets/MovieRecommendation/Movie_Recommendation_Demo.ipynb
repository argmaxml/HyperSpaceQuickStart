{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Recommednation System Using Hyperspace Engine\n",
        "This notebook demonstrates the use of Hyperspace engine to create a movie recommendation system, by first using classic search and then hybrid search, a combination of classic and vector searches, by combining  word embedding with metadata filtering.\n",
        "\n",
        "# The Datset\n",
        "The data is taken from [MovieLens Latest Datasets](https://grouplens.org/datasets/movielens/latest/) and was downloaded from [Kaggle movie recommender system dataset ](https://www.kaggle.com/code/rounakbanik/movie-recommender-systems). The data includes 40954 valid movies. The data is in SQL format (table) and will be converted to NoSQL (documents) format. The data preprocessing is given in the notebook titles \"MovieRecommendationDataPrep\", available in this repository.\n",
        "\n",
        "## Setting up the Hyperspace environment\n",
        "Setting the enviorment requires the following steps\n",
        "\n",
        "\n",
        "1.   Download and install the client API\n",
        "2.   Create data config file\n",
        "3. Connect to a server\n",
        "4.   Create collection\n",
        "5. Ingest data\n",
        "6. Run query"
      ],
      "metadata": {
        "id": "mv-I3CgcYxYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "username = \"yanivt@hyper-space.io\"\n",
        "password = 'gaU2Fs4h%NVj'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouog_PxYu1UK",
        "outputId": "85988178-a134-4678-ff2b-ca45131848eb"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'drive/MyDrive/Demos/MovieRecommendation/Movie_Recommendation_Processed.csv'"
      ],
      "metadata": {
        "id": "3hMAeRF6XWas"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install the Hyperspace client API\n",
        "\n",
        "Installation of Hyperspace cliend is straightforward and can be done using  standarad python modules, such as pip"
      ],
      "metadata": {
        "id": "OO5o1hkQZwk1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1p9reDKhndo",
        "outputId": "95c1633a-57de-4fda-96f8-415d093e07ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/hyper-space-io/hyperspace-py\n",
            "  Cloning https://github.com/hyper-space-io/hyperspace-py to /tmp/pip-req-build-lf3mmgdz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/hyper-space-io/hyperspace-py /tmp/pip-req-build-lf3mmgdz\n",
            "  Resolved https://github.com/hyper-space-io/hyperspace-py to commit e397b51e57fd6c3d83cdde8a8ed1b6b81d0509a7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (1.26.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (2.8.2)\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/hyper-space-io/hyperspace-py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Connect to Server\n",
        "The Hyperspace engine requires connection to a remote machine with pre-provided credendtials."
      ],
      "metadata": {
        "id": "a922B_TJVkAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hyperspace\n",
        "\n",
        "hyperspace_client = hyperspace.HyperspaceClientApi(host='https://search-master-demo.development.hyper-space.xyz',\n",
        "                                                   username=username, password=password)"
      ],
      "metadata": {
        "id": "0rMhrXILVg_M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that the cluster is live"
      ],
      "metadata": {
        "id": "jMBaZPVbjYsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_status = hyperspace_client.cluster_status()\n",
        "display(cluster_status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "w_efZPFEVxuL",
        "outputId": "470fe8d7-e17f-4ff2-c5b0-965027ee46d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'Collections size': {'CrimesInChicago': 308501,\n",
              "   'Movies': 0,\n",
              "   'all-MiniLM-L6-v2%20ArXiv%20titles': 376501},\n",
              "  'FPGA memory usage in GB': '0.2009GB',\n",
              "  'FPGA memory usage in percentage': '0.2009%',\n",
              "  'Hostname': 'hyperspace-demo-0',\n",
              "  'Number of total vectors': 685002},\n",
              " {'Number of data nodes': 1}]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create the Configuration file\n",
        "\n",
        "Similarly to other search databases, Hyperspace database requires a configuration file which outlines the data scheme."
      ],
      "metadata": {
        "id": "UU51tnzuWATM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "config = {\n",
        "  \"configuration\": {\n",
        "    \"adult\": {\n",
        "      \"type\": \"boolean\"\n",
        "    },\n",
        "    \"belongs_to_collection\": {\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"budget\": {\n",
        "      \"type\": \"integer\"\n",
        "    },\n",
        "    \"genres\": {\n",
        "      \"struct_type\": \"list\",\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"id\": {\n",
        "      \"type\": \"integer\"\n",
        "    },\n",
        "    \"original_language\": {\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"popularity\": {\n",
        "      \"type\": \"float\"\n",
        "    },\n",
        "    \"production_companies\": {\n",
        "      \"struct_type\": \"list\",\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"production_countries\": {\n",
        "      \"struct_type\": \"list\",\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"rating\": {\n",
        "      \"type\": \"float\"\n",
        "    },\n",
        "    \"release_date_unix_time\": {\n",
        "      \"type\": \"date\"\n",
        "    },\n",
        "    \"revenue\": {\n",
        "      \"type\": \"float\"\n",
        "    },\n",
        "    \"runtime_days\": {\n",
        "      \"type\": \"integer\"\n",
        "    },\n",
        "    \"spoken_languages\": {\n",
        "      \"struct_type\": \"list\",\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"title\": {\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "        \"description embedding\": {\n",
        "            \"type\": \"dense_vector\",\n",
        "            \"dim\": 2048,\n",
        "            \"index_type\": \"brute_force\",\n",
        "            \"metric\": \"IP\"\n",
        "      }\n",
        "  }\n",
        "}\n",
        "\n",
        "with open('MovieRecommendation_config.json', 'w') as f:\n",
        "    f.write(json.dumps(config, indent=2))\n",
        "\n"
      ],
      "metadata": {
        "id": "3SKjACJmWJNm"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# The NoSQL Dataset Fields\n",
        "The processed metadata includes the following fields:\n",
        "\n",
        "1.   **adult** [boolean] - states if the movie is rated 18+\n",
        "2.   **belongs_to_collection** [Keyword] - name of the collection that includes the movie. If the movie is not a part of a collection, value will be \"None\"\n",
        "3. **budget** [integer] - The budget of the movie in USD\n",
        "4. **genres** [list[Keyword]] - list of movie genres (i.e drama)\n",
        "5. **id** [integer]] - unique id per movie\n",
        "6. **original_language** [Keyword] - the original language in which the movie was produced\n",
        "7. **popularity** [float] - the popularity of the movie, formulated as an unbounded score\n",
        "8. **production_companies** [list[Keyword]] - list of production companies involved in the movie\n",
        "9. **production_countries** [list[Keyword]] - list of all countries in which the movie was filmed\n",
        "10. **rating** [float] - the movie IMDB weighted average rating  score\n",
        "11. **release_date_unix_time** [int] - the movie release date in unix time\n",
        "12. **revenue** [float] - the movie rvenue in [USD]\n",
        "13. **runtime_days** [int] - the number cinema run time days\n",
        "14. **spoken_languages** [list[Keyword]] - list of all languages spoken in the movie\n",
        "15. **title** [Keyword] - the movie title"
      ],
      "metadata": {
        "id": "_Kl0oodSh_Yb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gDLKKkcq26b"
      },
      "source": [
        "# **Loading the SQL data**\n",
        "We first load the movie metadata from a csv file, using the pandas module. The data was previously processed in order to only include the relevant features.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "df = pd.read_csv(data_path)\n",
        "df[\"runtime_days\"] = df[\"runtime_days\"].astype(int)\n",
        "df.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCs3k081qeQk",
        "outputId": "34e74d9d-370a-48d7-c473-bda76a34f261"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40951 entries, 0 to 40950\n",
            "Data columns (total 18 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   index                  40951 non-null  int64  \n",
            " 1   adult                  40951 non-null  bool   \n",
            " 2   belongs_to_collection  40951 non-null  object \n",
            " 3   budget                 40951 non-null  int64  \n",
            " 4   genres                 40951 non-null  object \n",
            " 5   id                     40951 non-null  int64  \n",
            " 6   overview               40951 non-null  object \n",
            " 7   popularity             40951 non-null  float64\n",
            " 8   production_companies   40951 non-null  object \n",
            " 9   production_countries   40951 non-null  object \n",
            " 10  revenue                40951 non-null  float64\n",
            " 11  runtime_days           40951 non-null  int64  \n",
            " 12  spoken_languages       40951 non-null  object \n",
            " 13  tagline                18454 non-null  object \n",
            " 14  title                  40951 non-null  object \n",
            " 15  year                   40951 non-null  int64  \n",
            " 16  rating                 40951 non-null  float64\n",
            " 17  unix_time              40951 non-null  int64  \n",
            "dtypes: bool(1), float64(3), int64(6), object(8)\n",
            "memory usage: 5.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word Embedding**\n",
        "The next step is to embedd the movie overview and the taglines. We will do a simple vectorization on the internal space of each column (in contrast to a more sophisticated embedding using,i.e., BERT or GPT). We will use the SKLEARN TfidfVectorizer. The first step will be to normalize the text and then replace rare words with base tense"
      ],
      "metadata": {
        "id": "fo0Q5qmIWijs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords = list(stopwords.words('english'))\n",
        "replacement_dict = {\"Cheated\":\"Cheat\",\"Photographs\":\"Photograph\",\"Awfully\":\"Awful\",\"Poisoner\":\"Poisoner\",\"comix\":\"comics\",\n",
        "                    \"embarrassingly\":\"embarrassing\"}\n",
        "\n",
        "def normalize_text(tagline):\n",
        "    tagline = re.sub(r'\\W', ' ', tagline)\n",
        "\n",
        "    words = nltk.word_tokenize(tagline)\n",
        "    normalized_words = [word for word in words if word.lower() not in ['be', 'is', 'are', 'am', 'was', 'were', 'been', 'being'] + stopwords]\n",
        "    normalized_words = [lemmatizer.lemmatize(word, pos='v') for word in normalized_words if len(word) > 1 and not word.isdigit()]\n",
        "\n",
        "    normalized_tagline = ' '.join(normalized_words)\n",
        "    for key in replacement_dict:\n",
        "      normalized_tagline = normalized_tagline.replace(key,replacement_dict[key])\n",
        "    return normalized_tagline\n",
        "\n",
        "df['tagline'] = df['tagline'].fillna(\"''\")\n",
        "df['tagline'] = df['tagline'].apply(normalize_text)\n",
        "df['overview'] = df['overview'].apply(normalize_text)\n",
        "replacement_dict = {\"Cheated\":\"Cheat\",\"Photographs\":\"Photograph\",\"Awfully\":\"Awful\",\"Poisoner\":\"Poisoner\",\"comix\":\"comics\",\n",
        "                    \"embarrassingly\":\"embarrassing\"}\n",
        "\n",
        "\n",
        "df[\"description text\"] = df[\"overview\"] + df[\"tagline\"]\n",
        "del(df[\"overview\"])\n",
        "del(df[\"tagline\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU7L4moRWksL",
        "outputId": "6c80cca3-3c4c-4883-9888-358911a29427"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_length = 2048\n",
        "def embedded_text(df_data, min_word_count):\n",
        "  tfidf = TfidfVectorizer(token_pattern=r'\\b\\w+\\b', stop_words=\"english\", min_df=min_word_count)\n",
        "  tfidf_matrix = tfidf.fit_transform(df_data)\n",
        "  idf_values = tfidf.idf_\n",
        "  top_terms_idx = idf_values.argsort()[::-1][:embedding_vector_length]\n",
        "  top_terms = [list(tfidf.vocabulary_.keys())[i] for i in top_terms_idx]\n",
        "  new_tfidf = TfidfVectorizer(vocabulary=top_terms)\n",
        "  new_tfidf_matrix = new_tfidf.fit_transform(df_data)\n",
        "  new_tfidf_matrix = round(100 * new_tfidf_matrix)/100\n",
        "  tfidf_matrix = new_tfidf_matrix.toarray()\n",
        "  new_col = df_data.copy()\n",
        "  return list(tfidf_matrix)\n",
        "\n",
        "df[\"description embedding\"] = embedded_text(df[\"description text\"], 10)\n",
        "df[\"description embedding\"] = df[\"description embedding\"].map(lambda x: list(x))\n",
        "df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "ENvNwg_2Wn8A"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Collection\n",
        "Collections are used to store data of similar context, etc."
      ],
      "metadata": {
        "id": "NGhQomDXq8zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Hyperspace engine can be done connecting to a remote machine with pre-provided credendtials. The process utilizes a pre-prepared configuration file which outlines the data structure"
      ],
      "metadata": {
        "id": "gvHyg32CVTyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_collections = True\n",
        "collection_name = 'Movies'\n",
        "\n",
        "if delete_collections:\n",
        "  if collection_name in cluster_status[0]['Collections size']:\n",
        "    hyperspace_client.delete_collection(collection_name)\n",
        "\n",
        "hyperspace_client.create_collection('MovieRecommendation_config.json', collection_name)\n",
        "hyperspace_client.cluster_status()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJELyDwapZmN",
        "outputId": "5a100ae2-a2e1-43df-c053-88af589f57d4"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Collections size': {'CrimesInChicago': 308501,\n",
              "   'Movies': 0,\n",
              "   'all-MiniLM-L6-v2%20ArXiv%20titles': 376501},\n",
              "  'FPGA memory usage in GB': '0.2008GB',\n",
              "  'FPGA memory usage in percentage': '0.2008%',\n",
              "  'Hostname': 'hyperspace-demo-0',\n",
              "  'Number of total vectors': 685002},\n",
              " {'Number of data nodes': 1}]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Ingestion"
      ],
      "metadata": {
        "id": "SoAn8EuqqmPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BATCH_SIZE = 500\n",
        "\n",
        "\n",
        "def chunker(df, size):\n",
        "    return (df.iloc[pos:pos + size] for pos in range(0, len(df), size))\n",
        "\n",
        "\n",
        "i = 0\n",
        "for chunk in chunker(df.iloc[i:], BATCH_SIZE):\n",
        "\n",
        "    batch = [hyperspace.Document(str(i + j), row) for j, row in enumerate(chunk.to_dict('records'))]\n",
        "\n",
        "    i += BATCH_SIZE\n",
        "\n",
        "    if i % BATCH_SIZE == 0:\n",
        "        response = hyperspace_client.add_batch(batch, collection_name)\n",
        "        batch.clear()\n",
        "        print(i, response)\n",
        "\n",
        "hyperspace_client.commit('Movies')\n",
        "\n"
      ],
      "metadata": {
        "id": "LorxCA0DsrLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ac1662-de95-413e-8edd-ba06d5d58987"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "1000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "1500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "2000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "2500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "3000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "3500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "4000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "4500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "5000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "5500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "6000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "6500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "7000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "7500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "8000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "8500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "9000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "9500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "10000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "10500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "11000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "11500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "12000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "12500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "13000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "13500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "14000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "14500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "15000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "15500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "16000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "16500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "17000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "17500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "18000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "18500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "19000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "19500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "20000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "20500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "21000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "21500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "22000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "22500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "23000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "23500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "24000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "24500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "25000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "25500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "26000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "26500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "27000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "27500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "28000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "28500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "29000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "29500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "30000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "30500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "31000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "31500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "32000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "32500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "33000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "33500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "34000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "34500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "35000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "35500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "36000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "36500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "37000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "37500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "38000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "38500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "39000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "39500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "40000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "40500 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n",
            "41000 {'code': 200, 'message': 'Batch successfully added', 'status': 'OK'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'code': 200, 'message': 'Dataset committed successfully', 'status': 'OK'}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating The Query\n",
        "Hyper Space queries are created in python format and saved as strings."
      ],
      "metadata": {
        "id": "42F0n4dLs0sq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#loading the score function"
      ],
      "metadata": {
        "id": "W5v7etLCFAo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score function encorporates logic based on movied budget and rating, and gives bonus to movies of similar production_companies. Only movies of the same genre are returned"
      ],
      "metadata": {
        "id": "r1zlEwGuQMWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sf_file = 'drive/MyDrive/Demos/MovieRecommendation/movies_score_function.py'\n",
        "hyperspace_client.set_function(sf_file, collection_name=collection_name, function_name='popular_films_recommendation')"
      ],
      "metadata": {
        "id": "z3trmq_WhggL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d02499-dacd-4eeb-b008-01d1d37b5e14"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'code': 200, 'message': 'Function was set successfully', 'status': 'OK'}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Running The Query**\n",
        "The next step is use the query logic and apply the query. We will run a vector search, followed by a hybrid search which includes analytic logic - boost based on rating, genres, etc. Let's start with vector search."
      ],
      "metadata": {
        "id": "_w_kr7POmgVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "ggrzx1WLtCZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5bdeaa1-5d38-4fc3-fd14-af67931927fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "searching for matches for ' Georgia '\n",
            "-------------------------------------------------\n",
            "Query run time = 98.9586ms\n",
            "-------------------------------------------------\n",
            "1 id 43 : Georgia\n",
            "2 id 17900 : Starlet\n",
            "3 id 10340 : License to Wed\n",
            "4 id 7152 : Sadie Thompson\n",
            "5 id 40662 : Eating\n",
            "6 id 26258 : Ever Since Eve\n",
            "7 id 40445 : Sadie's Last Days on Earth\n",
            "8 id 13719 : Miss Sadie Thompson\n",
            "9 id 38942 : Secrets of the Summer House\n",
            "10 id 3535 : Days of Wine and Roses\n",
            "11 id 22774 : The Devil's Widow\n",
            "12 id 34339 : In Search of Mozart\n",
            "13 id 7415 : Yours, Mine and Ours\n",
            "14 id 23909 : Sadie McKee\n",
            "15 id 9228 : Tartuffe\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from pprint import pprint\n",
        "\n",
        "input_vector = hyperspace_client.get_document(document_id='43', collection_name=collection_name)\n",
        "\n",
        "print(\"searching for matches for '\",input_vector[\"title\"],\"'\")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "query = {\n",
        "    'params': input_vector,\n",
        "    \"knn\": {\n",
        "        \"query\": {\"boost\": 0}, # boost = 0 , means no metadata filtering\n",
        "        \"description embedding\": {\n",
        "            \"boost\": 10,\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "results = hyperspace_client.search(query,\n",
        "                                        size=15,\n",
        "                                        function_name='popular_films_recommendation',\n",
        "                                        collection_name=collection_name)\n",
        "\n",
        "candidates = results['candidates']\n",
        "\n",
        "print(f\"Query run time = {results['took_ms']}ms\")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "for i, result in enumerate(results['similarity']):\n",
        "  api_response = hyperspace_client.get_document(document_id=result['document_id'], collection_name=collection_name)\n",
        "  print(i + 1, \"id\", result['document_id'],  \":\", api_response['title'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now with the Hybrid search"
      ],
      "metadata": {
        "id": "-8a2utcQTavM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pprint import pprint\n",
        "\n",
        "input_vector = hyperspace_client.get_document(document_id='43', collection_name=collection_name)\n",
        "\n",
        "print(\"searching for matches for '\",input_vector[\"title\"],\"'\")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "query = {\n",
        "    'params': input_vector,\n",
        "    \"knn\": {\n",
        "        \"query\": {\"boost\": 100}, # boost = 0 , means no metadata filtering\n",
        "        \"description embedding\": {\n",
        "            \"boost\": 1,\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "results = hyperspace_client.search(query,\n",
        "                                        size=15,\n",
        "                                        function_name='popular_films_recommendation',\n",
        "                                        collection_name=collection_name)\n",
        "\n",
        "candidates = results['candidates']\n",
        "\n",
        "print(f\"Query run time = {results['took_ms']}ms\")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "for i, result in enumerate(results['similarity']):\n",
        "  api_response = hyperspace_client.get_document(document_id=result['document_id'], collection_name=collection_name)\n",
        "  print(i + 1, \"id\", result['document_id'],  \":\", api_response['title'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyNbh77OTeJ8",
        "outputId": "d6fcd670-74e8-48c3-b6b7-0e98a7a40dfb"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "searching for matches for ' Georgia '\n",
            "-------------------------------------------------\n",
            "Query run time = 15.5327ms\n",
            "-------------------------------------------------\n",
            "1 id 10667 : There Will Be Blood\n",
            "2 id 11486 : Gran Torino\n",
            "3 id 11495 : Seven Pounds\n",
            "4 id 1365 : Good Will Hunting\n",
            "5 id 15416 : The Help\n",
            "6 id 1559 : Rain Man\n",
            "7 id 17089 : The Hunt\n",
            "8 id 1867 : American History X\n",
            "9 id 20845 : Boyhood\n",
            "10 id 2321 : American Beauty\n",
            "11 id 2410 : Fight Club\n",
            "12 id 8189 : Million Dollar Baby\n",
            "13 id 955 : One Flew Over the Cuckoo's Nest\n",
            "14 id 9644 : The Pursuit of Happyness\n",
            "15 id 999 : Dead Poets Society\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}