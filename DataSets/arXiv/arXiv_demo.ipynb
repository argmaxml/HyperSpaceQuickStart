{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Kone1nET7HS"
      },
      "source": [
        "#  Academic paper hybrid search with Hyperspace\n",
        "This notebook demonstrates the use of Hyperspace engine for a hybrid search for academic papers matching - a combination of vector search and keyword matching.\n",
        "\n",
        "# The Dataset\n",
        "The dataset is taken from [benchmarking sets]( https://github.com/qdrant/ann-filtering-benchmark-datasets#data) and includes a list of academic papers from arXiv, and their metadata.\n",
        "We will use the combination of an embedded vector data and metadata, to create a hybrid search.\n",
        "\n",
        "## Setting up the Hyperspace environment\n",
        "Setting the enviorment requires the following steps\n",
        "\n",
        "\n",
        "1. Download and install the client API\n",
        "2. Connect to a server\n",
        "3. Create data schema file\n",
        "4. Create collection\n",
        "5. Ingest data\n",
        "6. Run query"
],
      "id": "1Kone1nET7HS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEChRdiP1ygv"
      },
      "source": [
        "We mount a cloud folder which hosts the client files and install the client"
      ],
      "id": "LEChRdiP1ygv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZwFmp6tVLZ_"
      },
      "source": [
        "###Install the Hyperspace client API\n"
      ],
      "id": "SZwFmp6tVLZ_"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/hyper-space-io/hyperspace-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkkNOdYyZ7Ew",
        "outputId": "bfe7d687-c2b4-4f6c-f00f-dfacdd513f9c"
      },
      "id": "WkkNOdYyZ7Ew",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/hyper-space-io/hyperspace-py\n",
            "  Cloning https://github.com/hyper-space-io/hyperspace-py to /tmp/pip-req-build-5xvax89k\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/hyper-space-io/hyperspace-py /tmp/pip-req-build-5xvax89k\n",
            "  Resolved https://github.com/hyper-space-io/hyperspace-py to commit e397b51e57fd6c3d83cdde8a8ed1b6b81d0509a7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (1.26.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCZSwM6DVeDm"
      },
      "source": [
        "###Connect to Server\n",
        "\n",
        "Using the Hyperspace engine requires connection to a remote machine with pre-provided credendtials."
      ],
      "id": "TCZSwM6DVeDm"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "17a978a2"
      },
      "outputs": [],
      "source": [
        "import hyperspace\n",
        "\n",
        "hyperspace_client = hyperspace.HyperspaceClientApi(host='https://search-master-demo.development.hyper-space.xyz',\n",
        "                                                   username=username, password=password)"
      ],
      "id": "17a978a2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We check the status before proceeding"
      ],
      "metadata": {
        "id": "KiZGq3v8V4vL"
      },
      "id": "KiZGq3v8V4vL"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cH_lWsLLza0n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e5917232-b7c3-4e48-f17e-c330d375c002"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'Collections size': {'all-MiniLM-L6-v2%20ArXiv%20titles': 376501},\n",
              "  'FPGA memory usage in GB': '0.1045GB',\n",
              "  'FPGA memory usage in percentage': '0.1045%',\n",
              "  'Hostname': 'hyperspace-demo-0',\n",
              "  'Number of total vectors': 376501},\n",
              " {'Number of data nodes': 1}]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "cluster_status = hyperspace_client.cluster_status()\n",
        "display(cluster_status)"
      ],
      "id": "cH_lWsLLza0n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXmdh3YGVfQV"
      },
      "source": [
        "###Create the data schema file\n",
        "\n",
        "Similarly to other search databases, Hyperspace requires a data schema file which outlines the data schema."
      ],
      "id": "HXmdh3YGVfQV"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "976b2177"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "config = {\n",
        "    \"configuration\": {\n",
        "        \"id\": {\n",
        "            \"type\":\"float\"\n",
        "        },\n",
        "        \"title\": {\n",
        "            \"type\":\"keyword\"\n",
        "        },\n",
        "        \"submitter\": {\n",
        "            \"type\":\"keyword\"\n",
        "        },\n",
        "        \"categories\": {\n",
        "            \"type\":\"keyword\",\n",
        "            \"struct_type\":\"list\"\n",
        "        },\n",
        "        \"labels\": {\n",
        "            \"type\":\"keyword\",\n",
        "            \"struct_type\":\"list\"\n",
        "        },\n",
        "        \"license\": {\n",
        "            \"type\":\"keyword\"\n",
        "        },\n",
        "        \"update_date\": {\n",
        "            \"type\":\"keyword\"\n",
        "        },\n",
        "        \"update_date_ts\": {\n",
        "            \"type\":\"integer\"\n",
        "        },\n",
        "        \"embedded_abstract\": {\n",
        "            \"type\": \"dense_vector\",\n",
        "            \"dim\": 384,\n",
        "            \"index_type\": \"brute_force\",\n",
        "            \"metric\": \"IP\"\n",
        "        }\n",
        "    },\n",
        "    \"settings\": {\n",
        "      \"list_delimiter\": \",\"\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('arXiv_config.json', 'w') as f:\n",
        "    f.write(json.dumps(config, indent=2))\n",
        "\n"
      ],
      "id": "976b2177"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# The Dataset Fields\n",
        "The metadata includes the following fields:\n",
        "\n",
        "\n",
        "1.   id [float] - paper unique id\n",
        "2.   title [string] - paper title\n",
        "3. submitter [string] - name of person who submitted the paper\n",
        "4. categories [list[string]] - list of categories which include the paper\n",
        "5. label [list[string]] - labels aplied to paper\n",
        "6. license [string] - license type\n",
        "7. update_date_ts [integer] - update time in unix format\n",
        "\n",
        "We build a simple filtering function, which filters papers of the same category, gives bias to paper by same submitter an negative bias for papers without given license. We first select a paper as input for the query\n"
      ],
      "metadata": {
        "id": "M13x3LnlNCQd"
      },
      "id": "M13x3LnlNCQd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RTDkUsr3ead"
      },
      "source": [
        "### Create Collection\n",
        "Collections are used to store data of similar context, etc. We will erase the current collection, create a new one, and ingest data."
      ],
      "id": "7RTDkUsr3ead"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOj7VVTtlM_o"
      },
      "outputs": [],
      "source": [
        "delete_collections = False\n",
        "collection_name = 'all-MiniLM-L6-v2 ArXiv titles'\n",
        "\n",
        "if delete_collections:\n",
        "  if collection_name in cluster_status[0]['Collections size']:\n",
        "    hyperspace_client.delete_collection(collection_name)\n",
        "\n",
        "hyperspace_client.create_collection('arXiv_config.json', collection_name)\n",
        "hyperspace_client.cluster_status()"
      ],
      "id": "aOj7VVTtlM_o"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUpgHD2VWFXd"
      },
      "source": [
        "### Ingest data\n",
        "\n",
        "We load the datasets from and ingest it in batches of 500 data points (the batch size can be increased for faster ingestion)"
      ],
      "id": "lUpgHD2VWFXd"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "vecs = np.load('vectors.npy')\n",
        "metadata = open('payloads.jsonl')"
      ],
      "metadata": {
        "id": "2YfCosjCPGhl"
      },
      "id": "2YfCosjCPGhl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 500\n",
        "\n",
        "batch = []\n",
        "for i, (metadata_row, vec) in enumerate(zip(metadata, vecs)):\n",
        "    row = {key: value for key, value in json.loads(metadata_row).items() if key in config[\"configuration\"].keys()}\n",
        "    row['categories'] = row['categories'].split()\n",
        "    row['embedded_abstract'] = np.ndarray.tolist(vec)\n",
        "\n",
        "    batch.append(hyperspace.Document(str(i), row))\n",
        "\n",
        "    if i % BATCH_SIZE == 0:\n",
        "        response = hyperspace_client.add_batch(batch, collection_name)\n",
        "        batch.clear()\n",
        "        print(i, response)\n",
        "\n"
      ],
      "metadata": {
        "id": "aocQ5xgbZf-S"
      },
      "id": "aocQ5xgbZf-S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperspace_client.commit(collection_name)"
      ],
      "metadata": {
        "id": "cxmikitpnz5A"
      },
      "id": "cxmikitpnz5A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lRgTyKwWJ84"
      },
      "source": [
        "#Define Logic and Run a Query\n",
        "We will build a hybrid search query using Hyperspace. In the query,  we will randomly select a paper from the database and search for smilar papers."
      ],
      "id": "8lRgTyKwWJ84"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YdFBOCsOJka"
      },
      "outputs": [],
      "source": [
        "input_vector = hyperspace_client.get_document(collection_name, \"63\")\n",
        "print(input_vector['title'], \"\\n======================================\\n\", input_vector['submitter'], \"\\n\", input_vector['categories'])"
      ],
      "id": "0YdFBOCsOJka"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8l3bNPKbMfg"
      },
      "source": [
        "We run a query which combines similarity and vector search. The search fields can be given a weight in the query object. The final score of each search type willbe multiplied by the weight."
      ],
      "id": "U8l3bNPKbMfg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ff98e9d"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "response = hyperspace_client.set_function('/content/drive/MyDrive/Demos/ArXiv/arXiv_score_func.py', collection_name=collection_name, function_name='similarity_sf')\n",
        "\n",
        "query_with_knn = {\n",
        "    'params': input_vector,\n",
        "    \"knn\": {\n",
        "        \"query\": {\"boost\": 1}, # boost 0 means no run\n",
        "        \"embedded_abstract\": {\n",
        "            \"boost\": 10,\n",
        "            \"top_k\": 100,\n",
        "            \"nprobe\": 80\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "results = hyperspace_client.search(query_with_knn,\n",
        "                                        size=15,\n",
        "                                        function_name='similarity_sf',\n",
        "                                        collection_name=collection_name)\n",
        "\n",
        "for i, result in enumerate(results['similarity']):\n",
        "  api_response = hyperspace_client.get_document(document_id=result['document_id'], collection_name=collection_name)\n",
        "  print(i + 1, \"id\", result['document_id'],  \":\", api_response['title'], \",\", api_response['submitter'], \",\", api_response['categories'])\n",
        "  print(\"\\n\")\n"
      ],
      "id": "5ff98e9d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The returned documents have similar submitter name, as expected from the metadata filtering.\n",
        "\n",
        "This notebook gave a simple example of the use of the Hyperspace engine for hybrid search. Hyperspace can support complicated use cases with large databases, in extremley low latency."
      ],
      "metadata": {
        "id": "5uRO_8UUQIzk"
      },
      "id": "5uRO_8UUQIzk"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
