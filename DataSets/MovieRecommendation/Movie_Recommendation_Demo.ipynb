{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Recommednation System Using Hyperspace Engine\n",
        "This notebook demonstrates the use of Hyperspace engine to create a movie recommendation system, by first using classic search and then hybrid search, a combination of classic and vector searches, by combining  word embedding with metadata filtering.\n",
        "\n",
        "# The Dataset\n",
        "The data is taken from [MovieLens Latest Datasets](https://grouplens.org/datasets/movielens/latest/) and was downloaded from [Kaggle movie recommender system dataset ](https://www.kaggle.com/code/rounakbanik/movie-recommender-systems). The data includes 40954 valid movies. The data is in SQL format (table) and will be converted to NoSQL (documents) format. The data preprocessing is given in the notebook titles \"MovieRecommendationDataPrep\", available in this repository.\n",
        "\n",
        "## Setting up the Hyperspace environment\n",
        "Setting the enviorment requires the following steps\n",
        "\n",
        "\n",
        "1. Download and install the client API\n",
        "2. Connect to a server\n",
        "3. Create data schema file\n",
        "4. Create collection\n",
        "5. Ingest data\n",
        "6. Run query"
      ],
      "metadata": {
        "id": "mv-I3CgcYxYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'drive/MyDrive/Demos/MovieRecommendation/Movie_Recommendation_Processed.csv'"
      ],
      "metadata": {
        "id": "3hMAeRF6XWas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install the Hyperspace client API\n",
        "\n",
        "Installation of Hyperspace cliend is straightforward and can be done using  standarad python modules, such as pip"
      ],
      "metadata": {
        "id": "OO5o1hkQZwk1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1p9reDKhndo",
        "outputId": "95c1633a-57de-4fda-96f8-415d093e07ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/hyper-space-io/hyperspace-py\n",
            "  Cloning https://github.com/hyper-space-io/hyperspace-py to /tmp/pip-req-build-lf3mmgdz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/hyper-space-io/hyperspace-py /tmp/pip-req-build-lf3mmgdz\n",
            "  Resolved https://github.com/hyper-space-io/hyperspace-py to commit e397b51e57fd6c3d83cdde8a8ed1b6b81d0509a7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (1.26.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from hyperspace==1.0.0) (2.8.2)\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/hyper-space-io/hyperspace-py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Connect to Server\n",
        "The Hyperspace engine requires connection to a remote machine with pre-provided credendtials."
      ],
      "metadata": {
        "id": "a922B_TJVkAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hyperspace\n",
        "\n",
        "hyperspace_client = hyperspace.HyperspaceClientApi(host='https://search-master-demo.development.hyper-space.xyz',\n",
        "                                                   username=username, password=password)"
      ],
      "metadata": {
        "id": "0rMhrXILVg_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that the cluster is live"
      ],
      "metadata": {
        "id": "jMBaZPVbjYsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_status = hyperspace_client.cluster_status()\n",
        "display(cluster_status)"
      ],
      "metadata": {
        "id": "w_efZPFEVxuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create the data schema file\n",
        "\n",
        "Similarly to other search databases, Hyperspace database requires a configuration file which outlines the data schema."
      ],
      "metadata": {
        "id": "UU51tnzuWATM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "config = {\n",
        "  \"configuration\": {\n",
        "    \"adult\": {\n",
        "      \"type\": \"boolean\"\n",
        "    },\n",
        "    \"belongs_to_collection\": {\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"budget\": {\n",
        "      \"type\": \"integer\"\n",
        "    },\n",
        "    \"genres\": {\n",
        "      \"struct_type\": \"list\",\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"id\": {\n",
        "      \"type\": \"integer\"\n",
        "    },\n",
        "    \"original_language\": {\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"popularity\": {\n",
        "      \"type\": \"float\"\n",
        "    },\n",
        "    \"production_companies\": {\n",
        "      \"struct_type\": \"list\",\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"production_countries\": {\n",
        "      \"struct_type\": \"list\",\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"rating\": {\n",
        "      \"type\": \"float\"\n",
        "    },\n",
        "    \"release_date_unix_time\": {\n",
        "      \"type\": \"date\"\n",
        "    },\n",
        "    \"revenue\": {\n",
        "      \"type\": \"float\"\n",
        "    },\n",
        "    \"runtime_days\": {\n",
        "      \"type\": \"integer\"\n",
        "    },\n",
        "    \"spoken_languages\": {\n",
        "      \"struct_type\": \"list\",\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "    \"title\": {\n",
        "      \"type\": \"keyword\"\n",
        "    },\n",
        "        \"description embedding\": {\n",
        "            \"type\": \"dense_vector\",\n",
        "            \"dim\": 2048,\n",
        "            \"index_type\": \"brute_force\",\n",
        "            \"metric\": \"IP\"\n",
        "      }\n",
        "  }\n",
        "}\n",
        "\n",
        "with open('MovieRecommendation_config.json', 'w') as f:\n",
        "    f.write(json.dumps(config, indent=2))\n",
        "\n"
      ],
      "metadata": {
        "id": "3SKjACJmWJNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# The NoSQL Dataset Fields\n",
        "The processed metadata includes the following fields:\n",
        "\n",
        "1.   **adult** [boolean] - states if the movie is rated 18+\n",
        "2.   **belongs_to_collection** [Keyword] - name of the collection that includes the movie. If the movie is not a part of a collection, value will be \"None\"\n",
        "3. **budget** [integer] - The budget of the movie in USD\n",
        "4. **genres** [list[Keyword]] - list of movie genres (i.e drama)\n",
        "5. **id** [integer]] - unique id per movie\n",
        "6. **original_language** [Keyword] - the original language in which the movie was produced\n",
        "7. **popularity** [float] - the popularity of the movie, formulated as an unbounded score\n",
        "8. **production_companies** [list[Keyword]] - list of production companies involved in the movie\n",
        "9. **production_countries** [list[Keyword]] - list of all countries in which the movie was filmed\n",
        "10. **rating** [float] - the movie IMDB weighted average rating  score\n",
        "11. **release_date_unix_time** [int] - the movie release date in unix time\n",
        "12. **revenue** [float] - the movie rvenue in [USD]\n",
        "13. **runtime_days** [int] - the number cinema run time days\n",
        "14. **spoken_languages** [list[Keyword]] - list of all languages spoken in the movie\n",
        "15. **title** [Keyword] - the movie title"
      ],
      "metadata": {
        "id": "_Kl0oodSh_Yb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gDLKKkcq26b"
      },
      "source": [
        "# **Loading the SQL data**\n",
        "We first load the movie metadata from a csv file, using the pandas module. The data was previously processed in order to only include the relevant features.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "df = pd.read_csv(data_path)\n",
        "df[\"runtime_days\"] = df[\"runtime_days\"].astype(int)\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "fCs3k081qeQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word Embedding**\n",
        "The next step is to embedd the movie overview and the taglines. We will do a simple vectorization on the internal space of each column (in contrast to a more sophisticated embedding using,i.e., BERT or GPT). We will use the SKLEARN TfidfVectorizer. The first step will be to normalize the text and then replace rare words with base tense"
      ],
      "metadata": {
        "id": "fo0Q5qmIWijs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopwords = list(stopwords.words('english'))\n",
        "replacement_dict = {\"Cheated\":\"Cheat\",\"Photographs\":\"Photograph\",\"Awfully\":\"Awful\",\"Poisoner\":\"Poisoner\",\"comix\":\"comics\",\n",
        "                    \"embarrassingly\":\"embarrassing\"}\n",
        "\n",
        "def normalize_text(tagline):\n",
        "    tagline = re.sub(r'\\W', ' ', tagline)\n",
        "\n",
        "    words = nltk.word_tokenize(tagline)\n",
        "    normalized_words = [word for word in words if word.lower() not in ['be', 'is', 'are', 'am', 'was', 'were', 'been', 'being'] + stopwords]\n",
        "    normalized_words = [lemmatizer.lemmatize(word, pos='v') for word in normalized_words if len(word) > 1 and not word.isdigit()]\n",
        "\n",
        "    normalized_tagline = ' '.join(normalized_words)\n",
        "    for key in replacement_dict:\n",
        "      normalized_tagline = normalized_tagline.replace(key,replacement_dict[key])\n",
        "    return normalized_tagline\n",
        "\n",
        "df['tagline'] = df['tagline'].fillna(\"''\")\n",
        "df['tagline'] = df['tagline'].apply(normalize_text)\n",
        "df['overview'] = df['overview'].apply(normalize_text)\n",
        "replacement_dict = {\"Cheated\":\"Cheat\",\"Photographs\":\"Photograph\",\"Awfully\":\"Awful\",\"Poisoner\":\"Poisoner\",\"comix\":\"comics\",\n",
        "                    \"embarrassingly\":\"embarrassing\"}\n",
        "\n",
        "\n",
        "df[\"description text\"] = df[\"overview\"] + df[\"tagline\"]\n",
        "del(df[\"overview\"])\n",
        "del(df[\"tagline\"])\n"
      ],
      "metadata": {
        "id": "WU7L4moRWksL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_length = 2048\n",
        "def embedded_text(df_data, min_word_count):\n",
        "  tfidf = TfidfVectorizer(token_pattern=r'\\b\\w+\\b', stop_words=\"english\", min_df=min_word_count)\n",
        "  tfidf_matrix = tfidf.fit_transform(df_data)\n",
        "  idf_values = tfidf.idf_\n",
        "  top_terms_idx = idf_values.argsort()[::-1][:embedding_vector_length]\n",
        "  top_terms = [list(tfidf.vocabulary_.keys())[i] for i in top_terms_idx]\n",
        "  new_tfidf = TfidfVectorizer(vocabulary=top_terms)\n",
        "  new_tfidf_matrix = new_tfidf.fit_transform(df_data)\n",
        "  new_tfidf_matrix = round(100 * new_tfidf_matrix)/100\n",
        "  tfidf_matrix = new_tfidf_matrix.toarray()\n",
        "  new_col = df_data.copy()\n",
        "  return list(tfidf_matrix)\n",
        "\n",
        "df[\"description embedding\"] = embedded_text(df[\"description text\"], 10)\n",
        "df[\"description embedding\"] = df[\"description embedding\"].map(lambda x: list(x))\n",
        "df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "ENvNwg_2Wn8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Collection\n",
        "Collections are used to store data of similar context, etc."
      ],
      "metadata": {
        "id": "NGhQomDXq8zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Hyperspace engine can be done connecting to a remote machine with pre-provided credendtials. The process utilizes a pre-prepared configuration file which outlines the data structure"
      ],
      "metadata": {
        "id": "gvHyg32CVTyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_collections = True\n",
        "collection_name = 'Movies'\n",
        "\n",
        "if delete_collections:\n",
        "  if collection_name in cluster_status[0]['Collections size']:\n",
        "    hyperspace_client.delete_collection(collection_name)\n",
        "\n",
        "hyperspace_client.create_collection('MovieRecommendation_config.json', collection_name)\n",
        "hyperspace_client.cluster_status()"
      ],
      "metadata": {
        "id": "SJELyDwapZmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Ingestion"
      ],
      "metadata": {
        "id": "SoAn8EuqqmPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BATCH_SIZE = 500\n",
        "\n",
        "\n",
        "def chunker(df, size):\n",
        "    return (df.iloc[pos:pos + size] for pos in range(0, len(df), size))\n",
        "\n",
        "\n",
        "i = 0\n",
        "for chunk in chunker(df.iloc[i:], BATCH_SIZE):\n",
        "\n",
        "    batch = [hyperspace.Document(str(i + j), row) for j, row in enumerate(chunk.to_dict('records'))]\n",
        "\n",
        "    i += BATCH_SIZE\n",
        "\n",
        "    if i % BATCH_SIZE == 0:\n",
        "        response = hyperspace_client.add_batch(batch, collection_name)\n",
        "        batch.clear()\n",
        "        print(i, response)\n",
        "\n",
        "hyperspace_client.commit('Movies')\n",
        "\n"
      ],
      "metadata": {
        "id": "LorxCA0DsrLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating The Query\n",
        "Hyper Space queries are created in python format and saved as strings."
      ],
      "metadata": {
        "id": "42F0n4dLs0sq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the score function\n",
        "The score function encorporates logic based on movied budget and rating, and gives bonus to movies of similar production_companies. Only movies of the same genre are returned"
      ],
      "metadata": {
        "id": "W5v7etLCFAo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sf_file = 'movies_score_function.py'\n",
        "hyperspace_client.set_function(sf_file, collection_name=collection_name, function_name='popular_films_recommendation')"
      ],
      "metadata": {
        "id": "z3trmq_WhggL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Running The Query**\n",
        "The next step is use the query logic and apply the query. We will run a vector search, followed by a hybrid search which includes analytic logic - boost based on rating, genres, etc. Let's start with vector search."
      ],
      "metadata": {
        "id": "_w_kr7POmgVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggrzx1WLtCZm"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from pprint import pprint\n",
        "\n",
        "input_vector = hyperspace_client.get_document(document_id='47', collection_name=collection_name)\n",
        "\n",
        "print(\"searching for matches for '\",input_vector[\"title\"],\"'\")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "query = {\n",
        "    'params': input_vector,\n",
        "    \"knn\": {\n",
        "        \"query\": {\"boost\": 0}, # boost = 0 , means no metadata filtering\n",
        "        \"description embedding\": {\n",
        "            \"boost\": 10,\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "results = hyperspace_client.search(query,\n",
        "                                        size=15,\n",
        "                                        function_name='popular_films_recommendation',\n",
        "                                        collection_name=collection_name)\n",
        "\n",
        "candidates = results['candidates']\n",
        "\n",
        "print(f\"Query run time = {results['took_ms']}ms\")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "for i, result in enumerate(results['similarity']):\n",
        "  api_response = hyperspace_client.get_document(document_id=result['document_id'], collection_name=collection_name)\n",
        "  print(i + 1, \"id\", result['document_id'],  \":\", api_response['title'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now with the Hybrid search"
      ],
      "metadata": {
        "id": "-8a2utcQTavM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pprint import pprint\n",
        "\n",
        "input_vector = hyperspace_client.get_document(document_id='47', collection_name=collection_name)\n",
        "\n",
        "print(\"searching for matches for '\",input_vector[\"title\"],\"'\")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "query = {\n",
        "    'params': input_vector,\n",
        "    \"knn\": {\n",
        "        \"query\": {\"boost\": 100}, # boost = 0 , means no metadata filtering\n",
        "        \"description embedding\": {\n",
        "            \"boost\": 1,\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "results = hyperspace_client.search(query,\n",
        "                                        size=15,\n",
        "                                        function_name='popular_films_recommendation',\n",
        "                                        collection_name=collection_name)\n",
        "\n",
        "candidates = results['candidates']\n",
        "\n",
        "print(f\"Query run time = {results['took_ms']}ms\")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "for i, result in enumerate(results['similarity']):\n",
        "  api_response = hyperspace_client.get_document(document_id=result['document_id'], collection_name=collection_name)\n",
        "  print(i + 1, \"id\", result['document_id'],  \":\", api_response['title'])\n",
        "\n"
      ],
      "metadata": {
        "id": "WyNbh77OTeJ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
